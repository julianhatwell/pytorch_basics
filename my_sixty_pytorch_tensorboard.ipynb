{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "train_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "test_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4c83d9f9c5b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e7aeb1ea649c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(train_loader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(train_loader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
